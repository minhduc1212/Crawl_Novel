{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fbece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "ids = []\n",
    "new_urls = []\n",
    "with open(\"url.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "with open(\"url.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "with open(\"url.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "    urls= data['data']\n",
    "\n",
    "    urls = str(urls)\n",
    "    urls = urls.replace(\"-\", \"\")\n",
    "\n",
    "    pattern = r\"/(.*?)/\"\n",
    "    matches = re.findall(pattern, urls)\n",
    "    if matches:\n",
    "        for match in matches:\n",
    "            if match != '':\n",
    "                ids.append(match)\n",
    "    else:\n",
    "        print(\"Không tìm thấy đoạn văn bản phù hợp.\")\n",
    "for id in ids:\n",
    "    url = f\"https://sangtacviet.vip/truyen/fanqie/1/7441048283864108094/{id}/\"\n",
    "    new_urls.append(url)\n",
    "with open(\"new_url.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_urls, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6200424f",
   "metadata": {},
   "source": [
    "open new_url.json to get urls and paste it to STV_DLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d6c3d",
   "metadata": {},
   "source": [
    "Then, get new combine_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a50ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "new_data = []\n",
    "contents = ''\n",
    "content_path = os.path.join(os.getcwd(), 'content_1.txt')\n",
    "\n",
    "\n",
    "with open('combined_responses.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "    json_data = json.loads(data)\n",
    "\n",
    "    chapter_name = json_data['chaptername'].replace('\\n', '')\n",
    "    html_content = json_data['data']\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    content = soup.get_text(separator='\\n')\n",
    "    content = content.replace('@Bạn đang đọc bản lưu trong hệ thống', '')\n",
    "    content = content.replace('Bạn đang xem văn bản gốc chưa dịch, có thể kéo xuống cuối trang để chọn bản dịch.', '')\n",
    "    contents += chapter_name + '\\n' + '\\n' + content + '\\n' + '\\n'\n",
    "    \n",
    "with open(content_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(contents)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
